{"posts":[{"title":"Hello World 2025","text":"2024 是個值得紀錄的一年2023 年末，我離開了歐洲第一大的信用卡支付解決方案公司，加入了藍色巨人的行列。 隨著 2024 年工作量的增加，自我學習的難度也呈指數級提升，甚至連之前的筆記網站也已停更一年多。這讓我不禁思考：當軟體工程師停止自我學習的同時，是否也該重新檢視自己的生活與時間分配，是不是真的有達到 Work Life Balance？ 注意力是稀缺的資源 相較於時間分配，注意力是更稀缺的資源 我想這是我 2024 年最認同的話了，每天回到家後，想要投入新技術的學習，我總得先花大約 20 分鐘看 YouTube（或漫無目的逛蝦皮）才能真正進入狀態；有時甚至會直接選擇休息。這讓我回憶起念碩士、寫論文的日子，當時我竟能整天專注地閱讀論文、融會貫通，甚至舉一反三。 一來是現在可以分心的事情實在太多了，特別又在家班後的環境，實在很難不想放空。 二來是 注意力就像肌肉一樣，是要訓練的，念碩士時教授就有講，畢業後記得要持續念書，不然到最後連話都不會說了，或許 2025 年我該嘗試固定閱讀，看看這是否能真正提升我的注意力。 不過我也覺得這與個人的學習方法和習慣有關。我個人較喜歡 Top-down 的學習方式，先了解全局概況或各章節之間的關聯，再開始動手，就像撰寫 Side Project 時總想先規劃出完美的底層架構；但也可能因此，面對短期內用不到的知識時，我的注意力反而難以集中。 總結今年年初我終於重啟了第三版的 Knowledge Management，也花了一點時間研究 ppoffice 的 icarus Hexo Template，希望在 2025 年總結時能統計一下自己達成了哪些成就，並多分享與紀錄自己的所見所聞（不僅限於技術領域），同時也堅持自己的學習初衷： 我們不需要很厲害才能開始，但一定要開始後才能很厲害","link":"/2025/02/24/Hello-World-2025/"},{"title":"H2 資料庫測試出現 JdbcSQLSyntaxErrorException","text":"情境這幾天在測試 H2 資料庫用於單元測試，寫了一個 LoginVaildation (可參考我的 Github 專案)。 其中創建了 schema.sql &amp; data.sql 用於表的創建與資料的建置。 schema.sql 12345CREATE TABLE USER ( EMAIL VARCHAR(30) PRIMARY KEY, PXSSWORD VARCHAR(12), USERNAME NVARCHAR(30)); data.sql 1INSERT INTO USER (EMAIL, PXSSWORD, USERNAME) VALUES ('willy4543@gmail.com', 'Demo1234', 'William'); 執行後報出 JdbcSQLSyntaxErrorException 1Caused by: org.h2.jdbc.JdbcSQLSyntaxErrorException: Syntax error in SQL statement &quot;CREATE TABLE [*]USER ( EMAIL VARCHAR(30) PRIMARY KEY, PASSWORD VARCHAR(12), USER_NAME NVARCHAR(30) )&quot;; expected &quot;identifier&quot;; 原因USER 在 H2 內雖然不是 Table 的保留字，但 USER 是一個保留的標誌符 (identifier)，所以 H2 資料庫會把它當作當前登錄的用戶名稱。這就會導致指令出錯，拋出錯誤訊息告知在指令中出現了無效的標誌符。 解法把 TABLE 的名稱從 USER 更改為 PROJECT_USER 即可。 有時候這種來自小小設定的問題，似乎也只在遇到的時候記得，簡單紀錄一下。","link":"/2025/02/24/JdbcSQLSyntaxErrorException/"},{"title":"JPA 複合主鍵重複情境","text":"情境說明目前 JPA 幾乎是 Hibernate 框架的主流應用，內建 ORM 功能，並支援基礎的 findById、findAll 方法。 這週在支援其他案子時遇到一個奇怪的問題：使用 JPA 取資料時，結果出現了數筆重複資料。直覺上會以為是轉換成 DTO 時重複 set 資料導致，但實際觀察發現，有些資料會重複、有些不會。進一步追查才發現問題出在：使用複合主鍵 @Id + @IdClass 的情況下，主鍵值發生了重複。 原因來自 SA 設計資料表時，誤將 txn_time 當作唯一鍵值的一部分，實際資料卻沒有保證唯一性。 在理想情況下，Table 設計中複合主鍵應該構成一組真正的 PRIMARY KEY 或 UNIQUE KEY。然而理想很豐滿，現實很骨感，特別是新舊系統交接、資料遷移（Data Migration）時，常會出現這類不一致問題。 模擬資料1234567891011121314151617181920-- 建立資料表，且不設定 primary keyCREATE TABLE TXN_LOG ( product_name NVARCHAR(255), txn_time DATETIME NOT NULL, product_type NVARCHAR(50) NOT NULL, user_ixd NVARCHAR(50) NOT NULL);-- 插入資料（包含重複主鍵值）INSERT INTO TXN_LOG (product_name, txn_time, product_type, user_ixd) VALUES(N'信用卡繳費', '2025-04-07 10:00:00', 'PAYMENT', 'user001'),(N'信用卡繳費', '2025-04-07 10:05:00', 'PAYMENT', 'user002'),(N'Netflix 訂閱(A)', '2025-04-07 10:10:00', 'SUBSCRIPTION', 'user001'),(N'Spotify 訂閱', '2025-04-07 10:10:00', 'SUBSCRIPTION', 'user001'),(N'帳戶轉帳', '2025-04-07 10:20:00', 'TRANSFER', 'user002'),(N'Netflix 訂閱', '2025-04-07 10:25:00', 'SUBSCRIPTION', 'user003'),(N'信用卡繳費', '2025-04-07 10:30:00', 'PAYMENT', 'user004'),(N'Spotify 訂閱', '2025-04-07 10:10:00', 'SUBSCRIPTION', 'user001'),(N'帳戶轉帳', '2025-04-07 10:40:00', 'TRANSFER', 'user001'),(N'信用卡繳費', '2025-04-07 10:45:00', 'PAYMENT', 'user003'); Entity 與複合主鍵123456789101112131415161718192021@Entity@Data@IdClass(TxnLogEntityPk.class)@Table(name = &quot;TXN_LOG&quot;)public class TxnLogEntity implements Serializable { @Column(name = &quot;product_name&quot;) private String productName; @Id @Column(name = &quot;txn_time&quot;) private LocalDateTime txnTime; @Id @Column(name = &quot;product_type&quot;) private String productType; @Id @Column(name = &quot;user_ixd&quot;) private String userIxD;} 1234567891011@Data@AllArgsConstructor@NoArgsConstructorpublic class TxnLogEntityPk implements Serializable { private LocalDateTime txnTime; private String productType; private String userIxD;} 呼叫 findAll() 取得資料12345678910111213141516@Overridepublic List&lt;TxnLogRs&gt; getTxnLogList(TxnLogRq rq) { List&lt;TxnLogRs&gt; rsList = new ArrayList&lt;&gt;(); List&lt;TxnLogEntity&gt; entityList = txnLogRepository.findAll(); for (TxnLogEntity entity : entityList) { TxnLogRs rs = new TxnLogRs(); rs.setTxnTime(entity.getTxnTime()); rs.setProductType(entity.getProductType()); rs.setUserIxD(entity.getUserIxD()); rs.setProductName(entity.getProductName()); rsList.add(rs); } return rsList;} 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162[ { &quot;productName&quot;: &quot;信用卡繳費&quot;, &quot;txnTime&quot;: &quot;2025-04-07T10:00:00&quot;, &quot;productType&quot;: &quot;PAYMENT&quot;, &quot;userIxD&quot;: &quot;user001&quot; }, { &quot;productName&quot;: &quot;信用卡繳費&quot;, &quot;txnTime&quot;: &quot;2025-04-07T10:05:00&quot;, &quot;productType&quot;: &quot;PAYMENT&quot;, &quot;userIxD&quot;: &quot;user002&quot; }, { &quot;productName&quot;: &quot;Netflix 訂閱(A)&quot;, &quot;txnTime&quot;: &quot;2025-04-07T10:10:00&quot;, &quot;productType&quot;: &quot;SUBSCRIPTION&quot;, &quot;userIxD&quot;: &quot;user001&quot; }, { &quot;productName&quot;: &quot;Netflix 訂閱(A)&quot;, &quot;txnTime&quot;: &quot;2025-04-07T10:10:00&quot;, &quot;productType&quot;: &quot;SUBSCRIPTION&quot;, &quot;userIxD&quot;: &quot;user001&quot; }, { &quot;productName&quot;: &quot;帳戶轉帳&quot;, &quot;txnTime&quot;: &quot;2025-04-07T10:20:00&quot;, &quot;productType&quot;: &quot;TRANSFER&quot;, &quot;userIxD&quot;: &quot;user002&quot; }, { &quot;productName&quot;: &quot;Netflix 訂閱&quot;, &quot;txnTime&quot;: &quot;2025-04-07T10:25:00&quot;, &quot;productType&quot;: &quot;SUBSCRIPTION&quot;, &quot;userIxD&quot;: &quot;user003&quot; }, { &quot;productName&quot;: &quot;信用卡繳費&quot;, &quot;txnTime&quot;: &quot;2025-04-07T10:30:00&quot;, &quot;productType&quot;: &quot;PAYMENT&quot;, &quot;userIxD&quot;: &quot;user004&quot; }, { &quot;productName&quot;: &quot;Netflix 訂閱(A)&quot;, &quot;txnTime&quot;: &quot;2025-04-07T10:10:00&quot;, &quot;productType&quot;: &quot;SUBSCRIPTION&quot;, &quot;userIxD&quot;: &quot;user001&quot; }, { &quot;productName&quot;: &quot;帳戶轉帳&quot;, &quot;txnTime&quot;: &quot;2025-04-07T10:40:00&quot;, &quot;productType&quot;: &quot;TRANSFER&quot;, &quot;userIxD&quot;: &quot;user001&quot; }, { &quot;productName&quot;: &quot;信用卡繳費&quot;, &quot;txnTime&quot;: &quot;2025-04-07T10:45:00&quot;, &quot;productType&quot;: &quot;PAYMENT&quot;, &quot;userIxD&quot;: &quot;user003&quot; }] 你會發現重複的主鍵資料，JPA 只會保留第一筆，導致資料丟失或重複。 即使改用 JPQL 或 Native Query？12345@Query(&quot;SELECT r FROM TxnLogEntity r&quot;)List&lt;TxnLogEntity&gt; findAllTxnLogEntity();@Query(value = &quot;SELECT * FROM TXN_LOG&quot;, nativeQuery = true)List&lt;TxnLogEntity&gt; findAllTxnLogEntityWithNative(); 依然會有重複問題！ Hibernate/JPA 的底層解析Hibernate 背後維護一個 Persistence Context（即 Entity 一級快取），裡面用如下結構儲存 Entity： 1Map&lt;Serializable, Object&gt; entitiesById; 這裡的 key 就是你設定的主鍵（@Id 或 @IdClass），value 是對應的 Entity。 每當 Hibernate 從資料庫取出一筆 row，它會： 讀取主鍵組合 檢查是否已經有相同主鍵的 Entity 在快取中 有的話 -&gt; 跳過 or 覆蓋 沒有的話 -&gt; 加入 Map 所以如果主鍵欄位值重複，只會保留第一筆或最後一筆。 解法：使用 DTO 接資料若無法變更資料庫設計（或不能加上真正的主鍵/唯一鍵），最佳解法就是不用 Entity 當回傳型別，而是用自訂的 DTO 或 VO 來承接結果。 使用 JPQL constructor expression12@Query(&quot;SELECT new com.william.all_test.repository.dto.TxnLogDto(t.productName, t.txnTime, t.productType, t.userIxD) FROM TxnLogEntity t&quot;)List&lt;TxnLogDto&gt; findAllTxnLogToDto(); 接著用這些 DTO 組出回傳資料： 12345678910List&lt;TxnLogDto&gt; dtoList = txnLogRepository.findAllTxnLogToDto();for (TxnLogDto dto : dtoList) { TxnLogRs rs = new TxnLogRs(); rs.setTxnTime(dto.getTxnTime()); rs.setProductType(dto.getProductType()); rs.setUserIxD(dto.getUserIxD()); rs.setProductName(dto.getProductName()); rsList.add(rs);} 結果就會正確地包含每一筆資料，即使主鍵值重複，也不會被覆蓋掉，因為 JPA 不會把 DTO 當成持久化實體處理，也就沒有主鍵比對與快取問題。 這類問題其實在系統設計初期就可以避免，但實務上在資料遷移、系統整併或接手舊案時，仍很容易踩到坑。 若沒遇過這種狀況，Debug 起來真的會很崩潰，尤其是一直以為是 lambda、轉 DTO、list 重複 add 導致，然後卡在那裏核對快一個小時。 剛好這次遇到，把案例記錄下來。","link":"/2025/04/08/JpaDuplicateCompositeKey/"},{"title":"從霧裡來","text":"Cue Dependence 是一種記憶理論，由認知心理學家 Endel Tulving 提出，認為記憶形成時的線索，與未來檢索記憶時有密切的關係。 這些 cues 可能是場景，情緒，氣味，聲音，或是文字提示，幫助我們重新喚起記憶。 2025/2/19，我金門土生土長的漁夫阿公在家裡壽終正寢；不像我老家隔壁的伯公，在生命最後的清晨仍在海上灑網，直至天明時被海巡撈起，浪漫且悲壯。那天起家裡便要求外傭對阿公嚴加看管，好比把膠筏上馬達的鑰匙藏起來，只怕這片的海，最終都要收回他們。 我對阿公的印象就是一個典型舊時代男性，大男人，功利主義，對金錢十分執著；他曾用木筷指著玻璃空碗對兒時的我說，你知道什麼是飯桶嗎，就是只會吃飯的人，想想真是細思極恐；而年幼的我對阿公說，我現在是小孩沒本事賺錢，但我長大後要賺錢給阿公花，他笑得合不攏嘴，直到他失智的那段時間，依然能對我侃侃而談這段往事。 所以在入殮的那時，我們把各種幣別的鈔票撲滿他的身體，多到應該會通膨的那種，不知道那頭有沒有金管會能處理這件事。 接著父親在他耳邊說出藏匿馬達鑰匙的位置，就和當年外公火化前一樣，外婆把一管黑嘉麗軟糖放進他的口袋，輕聲地對他說不要再到廚房偷冰糖吃了。 想想真是好笑，笑得我滿眼都是淚，笑得我看不清楚紙鈔上的面額。 公祭當天，我手捧著要送給阿公的海釣俱樂部，可能都一直站著的原因，黑色的運動褲在我的腰上印出像東崗海灘上的水紋，這種痛癢感讓我想起小時候清明節回去的夜晚，我抓著紅透的皮膚起床找阿嬤，但她與阿公都消失在老家裡，只好搖醒哥哥一起爬上三樓，神壇上紅通的蠟燭與高掛的吳姓燈籠，本能地讓我們逃回樓下。後來我們抽出大門的木鞘，四月的霧就這樣湧進客廳，而我們走到大街上，直到霧氣吞沒我們的哭聲。 後來阿公帶著阿嬤從海邊回來了，肩上的扁擔掛著裝滿漁獲的橘色塑膠箱。阿嬤看我哭，一邊擦拭我臉上的淚，一邊說金門風大，早上起霧，中午就會出太陽的。 而今天清晨海平面也都是霧氣，中午太陽也好大好熱，但我知道他們再也不會從霧裡出現了。","link":"/2025/03/01/fromTheFog/"},{"title":"Orcale BD ORA-01704 string literal too long","text":"情境最近在做一些網路交易系統的開發，過程中需要不斷往 DB 塞入大量的法規 html 字串，取出後在前端再用 v-html 渲染。 範例 SQL12345678INSERT INTO DBP.CONTRACT_I18N(CONTRACT_ID, LOCALE, TITLE, CONTENT)VALUES ( 1, 'zh-TW', '數位網站&lt;br&gt;登入設施約定條款', TO_CLOB('&lt;div&gt;超長的法規條款內容&lt;/div&gt;'),); 在 INSERT 的時候 IDE ORA-01704: string literal too long 的訊息；忽然想到以前做專案的時候會在各段落間穿插 ') || TO_CLOB(' 來分段。 原因是 Oracle SQL 單一字串（VARCHAR2 literal） 最大只能 4000 bytes。而在 Oracle SQL Parser（語法解析階段）啟動時，TO_CLOB('...') 內的內容，在進入 TO_CLOB 函數之前，首先被當作 SQL String Literal 處理。所以超過 4000 bytes，Oracle 在 Parser 階段會直接報錯。 如果字串合法（≤ 4000 bytes），Oracle 才會把這個 String Literal 當成參數傳給 TO_CLOB()。 所以就改為: 12345678INSERT INTO DBP.CONTRACT_I18N(CONTRACT_ID, LOCALE, TITLE, CONTENT)VALUES ( 1, 'zh-TW', '數位網站&lt;br&gt;登入設施約定條款', TO_CLOB('&lt;div&gt;超長的法規條款內容1 ') || TO_CLOB(' 超長的法規條款內容2 ') || TO_CLOB(' 超長的法規條款內容3&lt;/div&gt;'),); 最後乾脆讓 AI 寫一個 Main 方法，之後包在測試工具類裡面。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import java.io.*;public class ToClobFormatter { public static void main(String[] args) { String inputFilePath = &quot;D:/tmp/target.txt&quot;; String outputFilePath = &quot;D:/tmp/result.txt&quot;; int chunkSize = 700; // 以「字數」切段 try (BufferedReader reader = new BufferedReader(new InputStreamReader(new FileInputStream(inputFilePath), &quot;UTF-8&quot;)); BufferedWriter writer = new BufferedWriter(new OutputStreamWriter(new FileOutputStream(outputFilePath), &quot;UTF-8&quot;))) { writer.write(&quot;TO_CLOB('&quot;); // 開頭先寫入 TO_CLOB int currentLength = 0; StringBuilder chunkBuffer = new StringBuilder(); String line; while ((line = reader.readLine()) != null) { // 保留原格式與換行，單引號轉義 String processedLine = line.replace(&quot;'&quot;, &quot;''&quot;) + &quot;\\n&quot;; int linePos = 0; while (linePos &lt; processedLine.length()) { int remaining = chunkSize - currentLength; int charsToTake = Math.min(remaining, processedLine.length() - linePos); chunkBuffer.append(processedLine, linePos, linePos + charsToTake); currentLength += charsToTake; linePos += charsToTake; if (currentLength &gt;= chunkSize) { writer.write(chunkBuffer.toString()); writer.write(&quot;')||TO_CLOB('&quot;); chunkBuffer.setLength(0); // 清掉buffer currentLength = 0; } } } // 最後剩下的寫出去 if (chunkBuffer.length() &gt; 0) { writer.write(chunkBuffer.toString()); } writer.write(&quot;')&quot;); // 收尾 } catch (IOException e) { e.printStackTrace(); } }}","link":"/2025/03/24/Ora01704/"},{"title":"Colorly | 1. 整合 Spring Cloud 的微服務專案","text":"Colorly 是一個正在開發中的 Spring Cloud + Vue3 的微服務專案，核心服務是提供用戶上傳照片，並返回一組該照片代表色的色碼 (使用 k-means 取五組)，開發的核心 Demo 如下: 剩餘的功能則類似 pinterest, 提供 Oauth 登入, 照片探索, 上傳與蒐藏。 主要目的是重新學習一整套 Spring Cloud 的 Solutions 和其他監控平台的應用，同時記錄相關的學習歷程，產出文件；身為台灣工程師的一份子，相信大家的老闆都希望你具備手搓火箭的能力，leetcode 刷個幾百題這樣…。 目前才剛做好核心的 api, 這裡先上服務的拓樸還有順手產出的相關文件 (後續會陸續更新…)，。 前言與閒聊記得 2021 年藉著之前公司跟 Azure Spring Cloud 產品測試的機會首次接觸 Spring Cloud 模組，當時花兩周研究並一套購票系統的 Demo 做 POC, 如今隨著工作時間的增長，Spring Cloud 模組也換了好幾代，當時使用的 Zulu Gateway, Hystrix 也都廢棄了，剛好趁目前空閒的期間重新學習一套 Spring Cloud 和監控平台的整合，發佈到自己的測試機器上(測試機也是買了好幾代…)。 說到 Colorly，其前身 Color Code Tag 其實是我在 2022 年刊登在 IT鐵人賽做 做 DevOps 練習的 Side Project, 一路用 Jenkins 打包儲存 container image 在 Harbor 內，部署到 linux 上面。從當時的兩台 Dell 7040m 到現在 AM4 和 X99 雙路… 這還真是一條不歸路阿。 這次預計重學 Spring Cloud 全家餐，Jaeger/Micrometer, EFK, Prometheus Grafana 講古和閒聊就到這裡，下一篇，我們正式開始介紹架構與設計思路，而各位觀眾老爺們若有任何問題或是發現要調整的地方，歡迎私訊我與我討論及勘誤 ~~","link":"/2025/06/10/colorly-1-intro/"},{"title":"Colorly | 2. Colorly 架構介紹","text":"Colorly 是一個提供照片代表色分析的 Web 專案, 其核心功能是讓用戶上傳照片, 由程式計算該照片之代表色碼, 並提供用戶上傳, 瀏覽, 蒐藏等功能。 本專案使用 Spring Cloud 微服務架構開發, 並提供相應的觀測平台。 後面經過一些調整後, 再次補充到 Infra Layer 的圖片, 整個伺服器唯一台 windows server, 裡面藉由 vmware 搭建數台 vm 分離環境, 並由 nginx 作為 reverse proxy。 而針對 uat 環境的 vm 與服務, 以及監控的 console 則不開放外部訪問, 僅於內網中使用與測試。 選用技術前端 Vue3 + ElementPlus Nginx reverse proxy 後端 Java 17 Spring Boot 3.4.5 Spring Cloud 2024.0.1 Spring Security + Oauth2 中間件 Consul 服務發現 RabbitMq 儲存 Mysql 8 Redis MinIO Bucket 監控平台 Jaeger + Microceter Promethues + Grafana EFK 設計上包含幾個重點: 以 Consul + Spring Cloud 做微服務的基礎架構 Redis 作為 jwt 後踢前與 service cache, lazy loading 使用 RabbitMq 用於非同步事件, OutBox Pattern 和 Error Log 處理 MinIO 用於儲存照片 後面的章節，我會挑選幾個重點內容分享","link":"/2025/06/11/colorly-2-arch/"},{"title":"Colorly | 3. 專案目錄結構 (Clean Architecture)","text":"相信身為一個 main Java 的 碼儂 火箭製造者，應該都用過 Controller、Service、Repository 經典的三層架構。這好上手，分層直觀，基本上照著寫，就算是剛畢業的新人也能輕鬆把功能跑起來。 用久了也不難發現它的限制，像是 Service 越寫越肥，一個 class 打開來幾千行（還沒寫註解）, 程式過手好幾個人變成縫合怪, 維護起來壓力山大, 為了把邏輯拆出去出現各種 helper 或 utils 類別來解耦。 到後期看到某段業務邏輯拆到 helper 裡，實際上那段邏輯只會被那個 Service 用到；或者是專案裡建立 BffUtils, BizUtils，聽起來像是共用的工具，其實裡面藏了不少跟特定業務綁死的邏輯。 接著身邊不少同事開始研究 (吹捧) DDD 搭配 Clean Architecture 更有彈性, 邏輯與技術解耦, 模組之間的邊界清晰等，後續要擴充或替換元件會輕鬆很多。 剛好藉這次 Side Project 的機會來實作一下, 主要參考 Tom Hombergs 的 Clean Architecture, 其中有部分調整的地方也會特別說明。 核心概念我認為 Clean Architecture 的實作有三大概念: 依賴方向保護核心邏輯 用語意建構程式架構 責任分離與加強替換性 下面我用一個進行中的範例來呈現: 常見作法是拆成 Entity、UseCase、Controller、Presenter、Gateway 這幾層, 而這裡把 UseCase 的邏輯放進了 Domain Layer 裡的 ImageService, 然後用 port 來取代 Gateway 的概念。 主要是 UseCase 相對單純, 未來再抽出來獨立維護。 整體流程大概是： Controller 接收照片後, 會先執行一連串的驗證（格式、大小、完整性等）, 驗證通過後, 將圖片資訊封裝成事件, 透過 MQ 發送給後續服務。 其中由 port 來定義需要的操作, ImageValidator、ImageIntegrityValidator 和 MessageQueuePublisher 三個 interface。就像是 對外的合約，負責描述 ImageService 需要哪些功能，但不關心底層實作。 實作部分則由 adapter 負責, 如 RabbitMQPublisher, 把實際怎麼驗證、怎麼送 MQ 的細節寫在 infrastructure layer, 如果未來要換掉 MQ 或改用另一套驗證邏輯，只要改 adapter implements 就好。 對應到剛剛說的三個核心概念: 依賴方向保護核心邏輯ImageService 只依賴 port interface，不會碰任何技術實作。這讓核心邏輯可以在完全不依賴框架、資料庫、MQ 的情況下運作與測試，也能在未來隨時替換 adapter 而不影響主流程。 用語意建構程式架構每個元件的命名都與實際業務流程對應，ImageValidator 驗證圖片、MessageQueuePublisher 發送事件 (但好像還能再優化一下)。 責任分離與加強替換性Controller、流程邏輯、技術實作這三層之間邊界清楚，測試時也能針對單一元件做 mock，不需要啟動整個應用程式。 另外在測試方面，我是設定用 Jacoco 做測試覆蓋率檢查，重點會放在： domain service、infra repo、adapter 做 unit test controller 則用 integration test 來跑整體流程 雖然開發時常會聽到大家推崇 TDD, 不過我自己體感下來, 很多人其實不是不會寫測試, 而是測試環境根本還沒準備好。例如資料庫沒用 test container, 測資不好造、mock 太麻煩等等, 會導致測試寫起來反而拖慢節奏。 雖然這些都有相應的解法, 但這部分測試相關的心得應該會再另外整理一篇來分享。 專案目錄結構說了這麼多, 就來上主菜吧。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200Colorly│├─.gitignore│ pom.xml│ ├─analytic-service (略)..│ ├─auth-service│ │ pom.xml│ │ │ └─src│ ├─main│ │ ├─java│ │ │ └─com│ │ │ └─colorly│ │ │ └─auth│ │ │ │ AuthApplication.java│ │ │ │ │ │ │ ├─application│ │ │ │ ├─controller│ │ │ │ │ AuthController.java│ │ │ │ │ │ │ │ │ └─dto│ │ │ │ LoginRq.java│ │ │ │ LoginRs.java│ │ │ │ OauthLoginRq.java│ │ │ │ │ │ │ ├─config│ │ │ │ SecurityConfig.java│ │ │ │ │ │ │ ├─domain│ │ │ │ ├─exception│ │ │ │ │ AuthServiceException.java│ │ │ │ │ │ │ │ │ ├─model│ │ │ │ │ AuthUser.java│ │ │ │ │ │ │ │ │ └─service│ │ │ │ │ AuthService.java│ │ │ │ │ CustomOidcUserService.java│ │ │ │ │ OAuth2AuthenticationSuccessHandler.java│ │ │ │ │ │ │ │ │ └─port│ │ │ │ OutboxPublisher.java│ │ │ │ │ │ │ └─infrastructure│ │ │ ├─adapter│ │ │ │ RabbitMqOutboxPublisher.java│ │ │ │ RabbitMqPublisher.java│ │ │ │ │ │ │ ├─filter│ │ │ │ JwtAuthFilter.java│ │ │ │ │ │ │ ├─persistence│ │ │ │ ├─entity│ │ │ │ │ OutboxEvent.java│ │ │ │ │ UserCredentialEntity.java│ │ │ │ │ │ │ │ │ └─repo│ │ │ │ OutboxEventRepository.java│ │ │ │ UserCredentialsRepository.java│ │ │ │ │ │ │ └─rabbitmq│ │ │ RabbitMQConfig.java│ │ │ │ │ └─resources│ │ application-uat.yml│ │ application.yml│ │ logback-spring.xml│ │ │ └─test│ ├─java│ │ └─com│ │ └─colorly│ │ └─auth│ │ │ RedisTestContainer.java│ │ │ │ │ ├─infrastructure│ │ │ └─repo│ │ │ OutboxEventRepositoryTest.java│ │ │ UserCredentialsRepositoryTest.java│ │ │ │ │ ├─integration│ │ │ AuthControllerTest.java│ │ │ │ │ ├─redis│ │ │ RedisTest.java│ │ │ │ │ └─security│ │ BCryptTest.java│ │ JwtUtilsTest.java│ │ │ └─resources│ application.yml│ ├─color-service(略)│ ├─common(略)│ ├─gateway │ │ pom.xml│ │ │ └─src│ ├─main│ │ ├─java│ │ │ └─com│ │ │ └─colorly│ │ │ └─gateway│ │ │ │ GatewayApplication.java│ │ │ │ │ │ │ ├─config│ │ │ │ GatewayRouteConfig.java│ │ │ │ SecurityConfig.java│ │ │ │ │ │ │ └─infrastructure│ │ │ └─filter│ │ │ JwtGatewayFilter.java│ │ │ │ │ └─resources│ │ application-uat.yml│ │ application.yml│ │ logback-spring.xml│ │ │ └─test│ └─java│ └─com│ └─colorly├─image-service│ │ pom.xml│ │ │ └─src│ ├─main│ │ ├─java│ │ │ └─com│ │ │ └─colorly│ │ │ └─image│ │ │ │ ImageApplication.java│ │ │ │ │ │ │ ├─application│ │ │ │ ├─controller│ │ │ │ │ ImageController.java│ │ │ │ │ │ │ │ │ └─dto│ │ │ │ ColorsRs.java│ │ │ │ │ │ │ ├─config│ │ │ ├─domain│ │ │ │ ├─exception│ │ │ │ │ ImageServiceException.java│ │ │ │ │ │ │ │ │ ├─model│ │ │ │ │ ColorClientRq.java│ │ │ │ │ ColorClientRs.java│ │ │ │ │ ImageIntegrityResult.java│ │ │ │ │ PhotoInfoMqDto.java│ │ │ │ │ │ │ │ │ └─service│ │ │ │ │ ImageService.java│ │ │ │ │ │ │ │ │ └─port│ │ │ │ ImageIntegrityValidator.java│ │ │ │ ImageValidator.java│ │ │ │ MessageQueuePublisher.java│ │ │ │ │ │ │ └─infrastructure│ │ │ ├─adapters│ │ │ │ ImageIntegrityValidatorImpl.java│ │ │ │ ImageValidatorImpl.java│ │ │ │ RabbitMQPublisher.java│ │ │ │ │ │ │ ├─client│ │ │ │ ├─config│ │ │ │ │ FeignTracingConfig.java│ │ │ │ │ │ │ │ │ └─feign│ │ │ │ ColorServiceClient.java│ │ │ │ │ │ │ └─rabbitmq│ │ │ RabbitMQConfig.java│ │ │ │ │ └─resources│ │ application-uat.yml│ │ application.yml│ │ logback-spring.xml│ │ │ └─test│ ├─java│ │ └─com│ │ └─colorly│ │ └─image│ │ └─infrastructure│ │ └─adapters│ │ ImageValidatorTest.java│ │ │ └─resources│ application.yml│ ├─storage-service (略)│ └─user-service (略) 最後其實架構沒有什麼絕對的對或錯, 只有符不符合團隊當下的需求。 套句我教授當年吐槽我的話, 你辛辛苦苦花一堆成本搞出這些東西, 結果沒多少人用, 還不是給老闆唾棄… 當年覺得他不可理喻, 現在慢慢能理解了, 但還是超不爽的 (笑~","link":"/2025/06/19/colorly-3-pjst/"},{"title":"Colorly | 4. 軟體開發生命週期 (Software Development Life Cycle, SDLC)","text":"SDLC（Software Development Life Cycle, 軟體開發生命週期）是一個用來描述開發軟體系統的完整流程與階段的模型。 Generally 涵蓋從規劃、設計、開發、測試、部署到維護, 用於確保開發效率與產出品質。而既然說到 週期, 代表 SDLC 不再是單一流程線，而是一個持續迭代的迴圈。 而 SDLC 也有多種實作的模型, 例如 Waterfall, Agile 等。近年來, 諸多專案藉由引入 Agile 與 DevOps，能在短週期內快速釋出功能，與適應變化, 可謂是強強聯手。我在先前參與信用卡系統開發時, 也強調將 Secure 整合到 SDLC 內, 是為安全軟體發展生命週期 (SSDLC)。 今天將以 Colorly 專案為例，逐步拆解 SSDLC 各階段在實務中如何落地，從點子到產出，從理論到程式, 開發節奏與工具如下： 短迭代敏捷開發：4 天為一個 Sprint，快速實作與驗證想法 Obsidian + Kanban 插件，追蹤 logback Markdown 記錄 API 與技術規格 Mermaid 繪製 API flow、系統架構圖 Flyway 控制資料庫 schema 版本 CI/CD 自動化流程 GitHub Action + Private Runner 自動化 Lint、測試 SonarQube 掃描 shell script 部署 部署驗證與測試 功能測試 老實說我覺得這一篇應該要放在第二篇的才對, 但是跑到第 4 週我覺得才比較穩定, 而且今天的文章主要是 Top-down 介紹 SDLC 與各方面的落地, 我想等之後更趨近穩定後再針對上面的內容獨立寫幾篇銀彈好了。 前置作業 (Scrumban, Git Strategy, Pipeline)Scrumban工欲善其事, 必先利其器, Sprint 1 &amp; 2 的目標是確認專案管理的方法, 搭建 devops pipeline 並 init-project 到最小可開發的情境。 首先是用 Obsidian + Kanban 插件, 並用 tag 分化出每個卡片的分類, 每個卡片在建立的時候都要註記它的範圍與產出, 其中 #plan 的卡片在完成設計後再拆分成數個子項目。 Sprint 週期是 3 + 1, 做一次 retrospective, 目標是把 WIP 從 Design 走到 release, 最後殘留的 TODO 項目放回 Backlogs 內。 但感覺一邊研究一邊實作, Backlogs 很快就會炸開就是了… Git Strategy &amp; Pipeline由於是單人開發, 這裡是先採用 github flow, 也就是從 main 內創建 feature 分支, 在 Sprint retro 時併回 main, 並部署到 uat 環境測試。在 github actions 中設定 on-commit feature-branch 需要通過 Quality Check, (理想中) 當 Code Coverage 未通過時, 是不能被 Merge 回 Main 的, 某方面也是強迫使用 TDD。 概念上和 Will 保哥在使用的分支策略類似。 因為是孤單威廉… 就自己 review 自己吧… (不過最近有導入 AI 跟 SonarQube) Pipeline 則貫穿四個環境，分別是本地開發的 Dev (我的筆電們), github repo, devops 機(Dell 7040m), 和 sit/uat 機(一台 Am4)。並在早期就把 EFK, Jeager 等觀測元件架設好, 待後續跟 application 連結。 目前剛搭建完 uat 的環境, 等 Prod 環境完成後, 再回來更新一份完整的 Git Branch Strategy (更新中…)","link":"/2025/06/23/colorly-4-sdlc/"},{"title":"Snowflake ID 跨前後端的整數精度問題","text":"情境最近在開發一款 Pos 系統的 Side Project, 由於是走微服務架構, 所以想採用 SnowflakeID 來確保全局唯一且趨勢遞增，避免自增 ID 對分庫分表的限制。 概念如下: 1 bit 41 bits 10 bits 12 bits 符號位 時間戳(ms) 機器ID 序列號 起始時間 2025-07-22 00:00:00 UTC = 1753056000000snowflake.atacenter-id=1 # 資料中心 ID (1-2)datacenter-id: 1 # 資料中心 ID (1-2 預設台北高雄各一台)machine-id: 3 # 機器 ID (1-2 預設每個 DC 各一台 VM) 大家對實作若有興趣可以參考我沒勘誤的文件(汗…) Casha Pos 內的 Snowflake ID 結果在測試的時候踩了一個很基本的坑, 由於後端直接回傳 id 為 Long 到前端以 number 承接, 導致 13729683518521345 在瀏覽器變成 13729683518521344。 原因JavaScript 的 Number 精度限制: • JSON 在瀏覽器端預設會用原生 JSON.parse，把數字解析成 JavaScript 的 Number（IEEE-754 double）。 • Number 的「安全整數」範圍只有：-2^53 ~ 2^53（上限 9007199254740991）。 • 只要超過這個範圍，parse 時就會「四捨五入」到最近可表示的整數，導致尾數失真。 • 例：13729683518521345 &gt; 9007199254740991，所以 parse 後會被四捨五入成 13729683518521344。 解法簡單來說就是修改 Long -&gt; String, 目前有兩個做法: 第一是直接在 Bff 的 Service 內置換 dto, 第二是在 Rs 上加入 @JsonSerialize(using = ToStringSerializer.class) 但建議還是乖乖換比較好。 結論原先的專案多數用 Auto Increment, 用到不小心忽略這個細節, 果然還是要定期複習前端, 真是汗顏…","link":"/2025/08/28/snowflakeId-frontend/"},{"title":"Casha | 1. 基於 Spring Cloud 的 F&amp;B 微服務專案","text":"Casha POS 是一套專為餐飲業 (F&amp;B) 打造的系統，採用 Spring Boot 3.4.8 與 Spring Cloud 2024 建構後端微服務，前端則以 Vue 3 + 組合式 API 搭配 Element Plus 開發。系統涵蓋後台管理、POS 點餐、KDS 廚房顯示與消費者自助點餐，並整合多種中介軟體與觀測工具，支援高併發交易與全鏈路監控。 目前把更多 好懶得整理 還在整理的筆記都放在 Github 中, 若對這個專案有興趣可以參考 ~~ 這一次寫這個專案也要驗證工作用到的技巧, 作為專案特色如下: 前後端分離 + BFF 模式：Admin、POS、KDS、Order App 各有專屬入口，降低耦合。 高併發交易處理：Redis + RabbitMQ 確保訂單高效能與可擴展。 全鏈路可觀測性：監控、日誌、追蹤工具整合，便於快速定位問題。 模組化設計：Auth、Store、Order、Analytic 各自獨立，支援服務擴展與水平擴容。 雲原生友好：服務與中介軟體均容器化，未來可支援 Kubernetes 部署。 完整 Pipeline &amp; SDLC : On-Premise devops 環境, 全權控管 Github Action runner, Harbor, SonarQube 規範, 定期 OWASP Top 10 檢測與修正, Jmeter 壓力測試與測報。 Applications1. 客戶端應用 (Client Apps) Admin Web：後台管理系統，用於帳號、權限與餐廳配置。 POS (尚未開放)：櫃台點餐端，處理訂單建立與結帳。 KDS (Kitchen Display System, 尚未開放)：廚房顯示端，接收訂單並支援出餐流程。 Order App (Web)：顧客使用的自助點餐 Web 應用，支援掃描 QRCode 下單。 2. 後端微服務 (Microservices) Spring Cloud Gateway：所有流量的入口，負責路由轉發、JWT 驗證、服務發現與 API 管控。 Admin-Portal：BFF，對接前端 Admin Web，負責與 Auth-Service、Store-Service 溝通。 Cis-Portal：BFF，服務 POS, Web App 與自助點餐應用，負責與 Order-Service 互動。 KDS-Portal：BFF，專為廚房顯示端設計，串接 Order-Service。 Auth-Service：身分驗證與權限管理，包含帳號、角色、權限控制。 Store-Service：餐廳與分店管理，包含菜單、座位、商品與 QRCode 設定，支援 MinIO 圖片檔案存取。 Order-Service：核心訂單服務，處理點餐、狀態流轉，並透過 RabbitMQ 進行訂單事件傳遞。 Analytic-Service：數據分析與報表，聚合交易與使用行為數據。 3. 中介軟體與基礎設施 (Middleware) Redis：快取服務，支援 session、token 與高頻查詢快取。 RabbitMQ：消息佇列，處理訂單事件與跨服務異步通信。 MinIO：S3 相容物件存儲，主要用於圖片、檔案上傳與存取。 4. 監控與可觀測性 (Observability/Monitoring) Jaeger：分散式追蹤，追蹤跨服務的請求鏈路。 Prometheus：指標收集，抓取 Spring Boot Actuator metrics。 Grafana：監控大盤，統一可視化。 ElasticSearch + Kibana：集中式日誌管理與查詢。 FluentBit：日誌收集與轉發。 On-Premise InfraStructure這一次的 DevOps 還是用當年的 Dell 7040m 架設 Harbor &amp; Github private runner 和 SonarQube, 而部署的機器就是自架的 Am4 平台(之前的 X99 實在太耗電…)。DevOps 和 Production 機器都在同一個網路環境內, 也方便部署。 Production 的伺服器是一台 windows server, 裡面藉由 vmware 搭建數台 vm 分離環境, 並由 nginx 作為 reverse proxy, 最外部則是使用我的網域 williamrightone.com 設定 CDN 與 cloudflare tunnel 做 https, C4-Model 如下: 系統互動流程 外部使用者 透過 Nginx 存取應用，請求由 Cloudflare 轉經 Nginx 代理至 Spring Cloud Gateway。 Gateway 與後端服務互動，連接 MySQL、Redis、RabbitMQ、Consul、ElasticSearch、MinIO 等中間件，實現完整業務流程。 Prometheus 定期抓取 Gateway 指標，Grafana 與 Jaeger 提供可視化監控與追蹤。 管理員透過 DBeaver、RedisInsight、Browser 等工具完成日常維運與監控工作。 Pipeline 在 main branch 下 tag 的時候觸發構建, 整個 SDLC 基本上和我之前的 Colorly 專案一致。 第一篇快速介紹了整個專案的架構, 下一篇則以 menu, order api 介紹核心的操作與下單流程, 並講解 redis 和 mq 從中扮演的角色與功用。","link":"/2025/09/14/casha-1-arch/"},{"title":"Casha | 2. RBAC, Menu &amp; Order api 等設計","text":"Casha 的 admin-portal 提供了一套能配置餐廳權限與設定菜單的功能, 今天就來介紹一下 admin-portal 的幾個核心設計: 管理平台, 餐廳, 分店的 RBAC 機制 座位與菜單的設計 最後再花約一半的篇幅介紹 order api。 開始前提醒, 因為篇幅過長的原因, 若有興趣可以直接到我的 git doc 內觀看 RBAC先看 ER Model: 以 ER Model 習慣的講法: 一個平台能有多個用戶, 每個用戶對應一組帳號每個帳號可以綁定一個或多個角色每個角色可以綁定多個權限每個權限會對應到一組 api 在 crud 上的操作, 並對應用戶在後台的功能清單 在 cahsa admin-portal 之中, 依照使用者的身分, 分為三個預設角色: 平台管理員 餐廳管理員 分店管理員 這三個預設的角色具備全部該範圍下的全部權限, 當平台管理員收到註冊請求後創立餐廳管理員, 該帳號即綁定餐廳全數權限, 同理, 餐廳在創建分店時, 亦生成預設的分店管理員帳號, 後續再由這些管理員創建同犯完角色時, 去綁定他們設定的角色與權限。 Note1. Spring Security角色所綁定的權限(Perminssion)會對應一支 api, 故在開發新功能的時候, 會需要將設定的 Perminssion Code 寫入 Controller 的 @PreAuthorize 內。 123456@PreAuthorize(&quot;hasAuthority('PLATFORM_FUNCTION_MGMT')&quot;)@PostMapping(&quot;/findAll&quot;)public ResponseEntity&lt;ApiResponse&lt;FindAllPermissionRs&gt;&gt; findAllPermissions() { FindAllPermissionRs rs = findAllPermissionUseCase.findAll(); return ResponseEntity.ok(ApiResponse.success(rs));} 2. User Session在整個 admin portal 中, 只有少部分 api 如登入, 註冊等不需要身分驗證, 而身分驗證成功後, 會在 redis 內創建 user session, 後續的 api 則在 gateway 驗證 jwt 成功後, 將 userAccount 放入 Header 後往 Bff 發送, 並在 Bff 層從 redis 內解析, 故在做相關的查詢的時候, 請求不需要特別帶 branch 或 restaurant Id。 123456789@PreAuthorize(&quot;hasAuthority('BRANCH_ITEM_MGMT')&quot;)@PostMapping(&quot;/findPage&quot;)public ResponseEntity&lt;ApiResponse&lt;FindItemsPageRs&gt;&gt; findPage( @RequestHeader(&quot;X-User-Account&quot;) String userAccount, @RequestBody FindItemsPageRq rq) { FindItemsPageRs rs = useCase.findPage(userAccount, rq); return ResponseEntity.ok(ApiResponse.success(rs));} 3. 身分驗證流程前面提到的 gateway 和 redis 等後踢前的效果, 核心是由 Auth-Service 頒發 jwt, 後續都由 gateway 進行驗證, 不用每次都再轉發到 Auth-Service 內, 但 gateway 和 auth-service 就要管理同一套 salt。 座位與菜單 1. 座位狀態不得不說, 在思考設計的時候才發現分店管理座位狀態的設計是 F&amp;B 系統非常核心的一塊。 一般常見的小型店面, 只要不須帶位的, 通常都會將 qrcode 貼在桌上, 所以點餐流程只需要集中處裡訂單即可。而需要帶位的店面則在 pos 上還需要仰賴座位狀態進行帶位, 常見的業務方法會即時生成一個共用的 qrcode 共同管理訂單狀態。 因此在設計後端座位管理的時候就要考量到, 這一套服務是要提供給上述哪一種需求的客戶, 又或是提供狀態選項, 平台全包。很不巧的我選擇了後者, 發現越做越複雜, 目前程式是依照 branch.visit_mode 來管理是否有追桌的行為, , 現在只先實作 DISABLED 不追桌, 若未來有時間可以再 refactor 與完善一下。 用戶掃碼下面這張圖是其中一間分店第二桌的 QR Code, 在完成座位設定後生成, 其 url 為 https://casha-order.williamrightone.com/m/o8qzmm4u2lurqfy2 在 url 中後面是該座位的 token, 經解密後可以取得 branch &amp; table Id, 在解析完成後攜帶分店資訊返回前端, 再轉導到菜單進行菜單查詢。 2. 菜單設計Casha 的菜單設計為 一個時間區間下所設定的單品與分類組合, 單品與分類為多對一, 相對直覺, 而菜單在建立後還需要配置各個版本, 給定菜單啟用的時間, 以及該時端要配置的分類與單品。 關於菜單的快取設計 Menu 是一個快取優先讀取 (Cache First) 的設計, 當第一個人訪問該 QR Code 並獲取菜單後, 菜單的內容與訊息便會儲存在 Redis Cache 內, 並且設定 180 ± (180 * 20%) 秒的 TTL (Time To Live), 來分散尖峰時刻 Cache 同時過期導致大量用戶請求湧入造成快取雪崩的風險; 而後面的用戶則會快取命中 (Cache Hit), 直接取用快取資料。 快取未命中 (Cache Miss) 時, 處理競爭鎖與重建快取 (Lock Competition &amp; Cache Rebuilding), 生成一個全域唯一的 lockToken（UUID），用於安全地釋放鎖, 並利用 Lua SET lockKey lockToken NX EX LOCK_EXPIRE_SECONDS 指令（經由 setIfAbsent 方法）原子性地嘗試獲取鎖, 同時給鎖設定一個較短的過期時間（3秒），防止持有鎖的執行緒崩潰導致鎖永遠無法釋放（死鎖）。 若成功獲取鎖, 先處理雙重檢查 (Double-Check), 避免成功獲取鎖的極短時間內，已經有另一個執行緒完成了快取重建並釋放了鎖；接著通過 Feign Client 呼叫 store-service 的 /resolveActive API 來獲取最新的菜單資料(也是整個流程中最耗時、成本最高的操作), 成功後將 Rs 轉換與寫入快取, 設置 TTL 抖動並返回結果。 若未能獲取鎖, 意味著已經有另一個執行緒正在重建快取, 退避等待 80ms 後再次嘗試讀取, 若等待後，快取依然為空（例如：持有鎖的執行緒執行非常慢，或在寫入快取前失敗了），則執行降級策略不再等待，而是直接降級呼叫下游服務。 最後當前成功獲取了鎖的執行緒，必須在 finally 程式碼塊中執行鎖釋放邏輯。 詳細內容可以到 git doc 內觀看 3. order api點餐的流程起自 用戶掃碼到顯示訂單完成, 前置作業要完成菜單的配置。上述提到用戶在掃碼後獲取餐廳與分店等訊息, 並取得菜單資訊，下一步便能在菜單上點餐並前往購物車結帳。 目前的設計沒有真正串接金流, 而是在前端自行發送一個 mock 的付款按鈕, 所以核心付款的 api 會是: /cis/order/create: 創建訂單, 支付前準備, 同時會最終確認存貨是否充足 /cis/payments/mock-callback: 模擬支付方付款成功時的 callbacl method 由於篇幅限制, 下面會稍微簡化, 若想看更詳細的流程歡迎到 git doc 內觀看 1. order/create這個 API 的核心目的是：處理使用者在點選「下單」或「結帳」按鈕後、實際發起支付前的所有準備工作。它是一個集「存貨驗證」、「最終計價」、「庫存預留」和「訂單創建」於一體的原子性操作。 該 api 在 BFF 層僅做轉發, 在 Biz 主要職責可分解為： 最終報價與鎖庫： 由 order-service 呼叫下游 store-service 進行最終的存貨檢查與計價，並預留庫存。 冪等性保證：防止因客戶端重試（如網路抖動、用戶雙擊）而導致重複下單。 創建訂單：將訂單資訊（含快照）持久化到資料庫，狀態為「已下單，未支付」(PLACED, UNPAID)。 綁定預留：將臨時的庫存預留令牌與剛創建的正式訂單綁定，為後續的支付成功/失敗處理做準備。 支付超時管理：發送一個延遲消息，設定支付時限（如15分鐘），超時後系統將自動取消訂單並釋放預留的庫存。 其最終目標是生成一個待支付的訂單，並確保在支付過程中，用戶所見的價格和庫存是確定的、被臨時鎖定的。 2. payments/mock-callback理支付提供商發送的非同步支付結果通知，並根據結果更新訂單狀態、驅動後續業務流程（如庫存結算或釋放）。 它是一個冪等的操作，需要妥善處理以下情況： 支付成功：將訂單狀態更新為「已支付」，並觸發庫存預留轉為實際銷售的流程。 用戶取消：用戶在支付過程中主動取消，立即釋放預留的庫存。 支付失敗：支付因各種原因失敗，保持訂單為「未支付」狀態，等待超時流程來處理。 重複通知：支付提供商可能重複發送通知，API 必須能識別並正確處理已處理過的訂單。 全流程最後來張超大的流程圖。 結語花了滿長的篇幅介紹 order &amp; payment 的機制, 現在 Jmeter 壓力測試業在如火如荼的進行中, 測試後除了記錄觀測平台外, 也能用測資來調整後續報表的設計。 預計下一篇會介紹 Jmeter 的實作和 Grafana/Prometheus 的設置, 並看看在當前的設計下, 我的服務表現如何 (汗…)。","link":"/2025/09/15/casha-2-api/"},{"title":"Casha | 3. Jmeter 壓力測試與監控（Baseline + Capacity &#x2F; Grafana, Prometheus)","text":"關於壓力測試, 會注重於在特定情境之下, 系統能夠運行的極限。其中比較費工的點分為 TestCase 的定義, 以及事前的準備, 這些都需要在執行之前有完善的計畫。 本報告彙整 Scan→Menu 與 Scan→Menu→Order（含付款回調） 兩條路徑的基準/容量測試與監控觀察，重點在：可穩定承載的 RPS/併發、延遲 SLA（p50/p95/p99）、錯誤率、依賴服務健康度。 關於 JMX 和用 Procedure 建立假資料則收錄在 git doc 監控與壓力測試報告（Baseline + Capacity） 內。 0. 測試環境與共用設定 執行環境：Local（AMD R5 4600H / 32GB RAM），各服務 單實例。 負載模型：Ultimate Thread Group，五段階梯並發100 → 200 → 400 → 600 → 800 users每段：Startup 60s / Hold 300s / Shutdown 30s。 使用者行為腳本（共用） 一次掃碼 → /cis/seat/resolve 菜單刷新 2–3 次（每 3–7s） → /cis/menu/active 建立訂單（隨機 1–3 個商品、每個 qty=1~3） → /cis/order/create 模擬付款回調 → /cis/payments/mock-callback 量測指標：p50/p95/p99、Error%、TPS、各服務 p95、CPU/Heap、Redis Ops/Hit Ratio、MQ Queue Depth。 在前面的章節: 菜單設置與快取機制 中有提到, 在首次解析該qrcode 時, 會真的到 DB 內查詢, 儲存到 Redis 後返回, 後面的請求則在 Data TTL 前都使用 Redis 的資料。 1. Scan→Menu 基準/容量（Baseline + Capacity）目標：針對讀路徑（Scan→Menu）量出固定資源下可穩定承載的 RPS，並給出 p50/p95/p99 SLA。輸出：各階段（100/200/400/600/800 users）之延遲分佈、錯誤率、依賴服務健康度，與結論（穩定承載 RPS、建議 SLA）。 1.1 測試模型與資料規模 分店：800 間，每店 5 桌 → 4,000 QR 菜單版本：每店 1 版，共 800 版 品項：每版 10 品項（3 分類），全部緩存在 Redis（首刷命中 DB，TTL 內皆走 Redis） 使用者行為：抵達後掃碼 1 次；在 5 分鐘 Hold 期間，每 3–7 秒刷新菜單；段尾逐步退出，進入下一並發段。 設計目的：最大化讀路徑覆蓋，反映「高頻看菜單」的真實流量型態。 1.2 結果（JMeter） Error% 中觀察到的 Response was null 判定為 JMeter 偶發、非伺服器錯誤（Error% 1.44% &lt; 2%）。 ResolveSeat（掃碼）p50 ≈ 45 ms / p95 ≈ 60 ms / p99 ≈ 85 ms / Error% = 0%需觸發 DB 與狀態解析，延遲高於菜單，但仍 &lt; 100 ms 且只發生一次，體驗可接受。 MenuRefresh（核心讀菜單）p50 ≈ 12 ms / p95 ≈ 22 ms / p99 ≈ 67 ms / Error% ≈ 1.44%低毫秒級，Redis 快取表現穩定，tail latency 無明顯拖尾。 Label #Samples Error % Avg (ms) p90 p95 p99 TPS ResolveSeat 4,200 0.00% 56.90 88 112 160 2.59 MenuRefresh 262,503 0.00% 16.30 22 29 92 134.8 Total 138,605 0.00% 19.20 20 26 77 71.1 1.3 監控觀察（Grafana/Prometheus） QPS by Service：峰值約 130–140 req/s（主在 cis-service），其餘服務 20–40 req/s，負載分布合理。 p95：cis-service（含 seat/resolve + menu/active）&lt; 100 ms；整體 &lt; 200 ms，符合常見 SLA。 CPU/Heap：各服務 CPU 峰值 &lt; 6%；Heap 約 1.0–1.7%，GC 無異常；Redis Ops 峰值 ~300 ops/s、Hit Ratio 100%。 1.4 結論（Scan→Menu） 在 800 並發（~75 RPS） 條件下，MenuRefresh p95 ≈ 22 ms、p99 ≈ 67 ms，Error% &lt; 2%。 穩定承載能力：保守建議 ≥ 70–80 RPS；讀路徑 SLA 可訂 p95 ≤ 25 ms、p99 ≤ 70 ms、Error% &lt; 2%。 資源使用率低，尚有擴容空間。 2. Scan→Menu→Order 基準/容量（Baseline + Capacity）目標：在多分店 open model 下，量測端到端（掃碼→看菜單→下單→回調）的延遲與穩定度。測資假設（每店）：10 商品、可銷售量總和 725；每位用戶下單 2–3 商品（qty=1）。 2.1 兩組情境 性能 SLA baseline（50 店）：確保 800 users 後仍有庫存，以量 延遲/TPS/錯誤率。 正確性 baseline（7 店）：總可售量 7×725=5,075，在後段階段必然售罄，用以驗證 正確拒絕與無超賣。 整場 5 段合計 2,100 users，若以 2.5 件/人估算，約 5,250 件 請求量。 2.2 結果（JMeter）a) 50 店（性能） CreateOrder：Avg 129 ms / p95 255 ms / p99 394 ms / Error% 0% MockCallback：Avg 54 ms / p95 106 ms / Error% 0% MenuRefresh：如 §1 結果，持續低毫秒級 Label #Samples Error % Avg (ms) p90 p95 p99 TPS ResolveSeat 4,200 0.00% 56.90 88 112 160 2.59 MenuRefresh 262,503 0.00% 16.30 22 29 92 134.8 CreateOrder 2,100 0.00% 129.10 211 255 394 1.30 MockCallback 2,100 0.00% 53.90 85 106 149 1.30 Total 138,605 0.00% 19.20 20 26 77 71.1 監控：QPS 峰值 130–140；order-service p95 100–150 ms；CPU &lt; 6%、Heap &lt; 2%、Redis Ops 峰值 ~600。 結論（50 店）：在 800 users 下，端到端 Error = 0%、CreateOrder p95 ≈ 255 ms；可對外主張 穩定承載 ≈ 130 TPS、p95 &lt; 300 ms。 b) 7 店（正確性） 預期：累計到第 4–5 段總購買量 &gt; 5,075，進入售罄。 CreateOrder Error% ≈ 20.8% 為 400 / CIS00004（售罄），屬於「正確拒絕」。 MockCallback Error% ≈ 32.6%（因前一步未下單成功，自然無回調對象）。 DB 校驗：sum(menu_version_item.daily_quota) = 5,075sum(sales_quota_counter.used_qty) = 5,075 → 完全一致，證實無 oversell。 Label #Samples Error % Avg (ms) p90 p95 p99 TPS ResolveSeat 4,200 0.0% 46.10 62 74 104 2.59 MenuRefresh 262,696 0.0% 12.10 15 17 28 134.8 CreateOrder 2,100 20.8% 82.60 120 137 176 1.30 MockCallback 2,100 32.6% 40.40 58 73 96 1.30 Total 138,700 0.8% 14.10 16 18 27 71.2 監控：QPS 120–140；order-service p95 ~150 ms，cis-service &lt; 100 ms；CPU 峰值 &lt; 6%、Heap 緩升但 &lt; 2%；Redis Hit 100%。 結論（7 店）：在受限庫存場景下，系統正確拒絕售罄下單、前端菜單同步 isActive=0，且 未發生超賣；延遲/資源保持穩定。 3. 綜合結論與建議 可穩定承載能力 讀路徑（Scan→Menu）：穩定承載 ≥ 70–80 RPS，建議 SLA：p95 ≤ 25 ms / p99 ≤ 70 ms / Error% &lt; 2%。 下單路徑（Scan→Menu→Order）：在 ~130 TPS 時，CreateOrder p95 &lt; 300 ms、Error ≈ 0%（50 店）。 正確性 在 7 店（5,075 件） 受限場景，售罄後返回 400/CIS00004，DB 統計與可售量一致，證實 無 oversell。 資源/依賴健康度 CPU/Heap/Redis/MQ 均遠離瓶頸，說明單機資源足夠、系統可擴空間大。 差異解讀 JMeter p95（單純 HTTP Sampler 延遲） vs. Grafana p95（含 gateway/metrics）存在落差，屬正常量測口徑差異。 下一步建議 Stress/Break Test：每 3–5 分鐘上調 20–30% RPS，直到 Error% &gt; 5% 或 p99 爆炸，找臨界點與優雅降級行為。 熱門品/熱鍵測試：權重選品，驗證 Redis/DB 熱點行為。 容量預估：以本次曲線外推，規劃 2×–3× 擴容策略（服務副本/連線池/隊列上限）。 目前僅跑完 Baseline 測試, 驗證在設想的情境之下, 菜單的快取設置以及點餐的原子性都有成功的發揮，後面再找時間直接在 AM4 平台上跑更多的 Thread Group 去測試, 看看目前系統的極限。","link":"/2025/09/16/casha-3-ptom/"},{"title":"Casha | 4. Saga Pattern 介紹 - 餐廳與帳號創建","text":"Cash Pos 在微服務的分布式事務上, 使用了 Orchestration Saga, 也藉這個機會介紹和紀錄一下 Saga Pattern 實作的方法。 關於 Saga在微服務架構中，傳統的 ACID 事務無法跨越多個服務，Saga 模式就為了解決這個問題而誕生。 Saga 的核心概念是: 把一個長交易切成一連串的本地交易 (Local Transaction) 若其中某一步失敗，就觸發對應的補償行為 (Compensation), 回滾已完成的步驟，達到最終一致性 目前主要有兩種實作的風格: Choreography Saga (協作式) &amp; Orchestrated Saga (協調式) Choreography Saga (協作式)核心是事件驅動, 各服務靠事件彼此觸發 (每個服務完成工作後發布事件，其他服務監聽並反應), 優點是服務耦合度低, 但因為流程分散在事件之間, 遇到複雜流程的時候比較難處理。 由於每個服務只監聽自己關心的事件, 通常適用事件導向、步驟可獨立演進的情境。 好比用戶註冊的流程: 建立用戶帳號 (Auth Service) 發送歡迎郵件 (Mail Service) 建立用戶個人檔案 (User Service) 補償協調 建立用戶帳號123456789101112131415161718192021222324252627282930313233343536373839@Service@Slf4jpublic class UserService { @Autowired private ApplicationEventPublisher eventPublisher; public void registerUser(RegisterUserCommand command) { log.info(&quot;開始註冊用戶: {}&quot;, command.getEmail()); // 1. 建立用戶帳號 User user = User.builder() .userId(generateUserId()) .email(command.getEmail()) .password(command.getPassword()) .status(&quot;ACTIVE&quot;) .createdAt(LocalDateTime.now()) .build(); userRepository.save(user); // 2. 發布 UserRegistered 事件 UserRegisteredEvent event = UserRegisteredEvent.builder() .userId(user.getUserId()) .email(user.getEmail()) .timestamp(LocalDateTime.now()) .build(); eventPublisher.publishEvent(event); log.info(&quot;用戶註冊成功，發布事件: {}&quot;, user.getUserId()); } // 處理註冊失敗的補償 @EventListener public void handleRegistrationFailed(RegistrationFailedEvent event) { log.info(&quot;收到註冊失敗事件，刪除用戶: {}&quot;, event.getUserId()); userRepository.deleteById(event.getUserId()); }} 發送歡迎郵件12345678910111213141516171819202122232425262728@Service@Slf4jpublic class EmailService { @EventListener public void handleUserRegistered(UserRegisteredEvent event) { log.info(&quot;收到用戶註冊事件，發送歡迎郵件: {}&quot;, event.getEmail()); try { // 發送歡迎郵件 sendWelcomeEmail(event.getEmail(), event.getUserId()); log.info(&quot;歡迎郵件發送成功: {}&quot;, event.getEmail()); } catch (Exception e) { log.error(&quot;發送歡迎郵件失敗: {}&quot;, event.getEmail(), e); // 發布郵件發送失敗事件 EmailFailedEvent failedEvent = EmailFailedEvent.builder() .userId(event.getUserId()) .email(event.getEmail()) .reason(&quot;郵件發送失敗: &quot; + e.getMessage()) .timestamp(LocalDateTime.now()) .build(); eventPublisher.publishEvent(failedEvent); } }} 建立用戶個人檔案123456789101112131415161718192021222324252627282930313233343536373839404142@Service@Slf4jpublic class UserService { @EventListener public void handleUserRegistered(UserRegisteredEvent event) { log.info(&quot;收到用戶註冊事件，建立個人檔案: {}&quot;, event.getUserId()); try { // 建立預設個人檔案 UserProfile profile = UserProfile.builder() .userId(event.getUserId()) .email(event.getEmail()) .displayName(event.getEmail().split(&quot;@&quot;)[0]) // 使用信箱前綴作為顯示名稱 .createdAt(LocalDateTime.now()) .build(); profileRepository.save(profile); log.info(&quot;個人檔案建立成功: {}&quot;, event.getUserId()); } catch (Exception e) { log.error(&quot;建立個人檔案失敗: {}&quot;, event.getUserId(), e); // 發布個人檔案建立失敗事件 ProfileCreationFailedEvent failedEvent = ProfileCreationFailedEvent.builder() .userId(event.getUserId()) .email(event.getEmail()) .reason(&quot;個人檔案建立失敗: &quot; + e.getMessage()) .timestamp(LocalDateTime.now()) .build(); eventPublisher.publishEvent(failedEvent); } } // 處理註冊失敗的補償 @EventListener public void handleRegistrationFailed(RegistrationFailedEvent event) { log.info(&quot;收到註冊失敗事件，刪除個人檔案: {}&quot;, event.getUserId()); profileRepository.deleteByUserId(event.getUserId()); }} 補償協調1234567891011121314151617181920212223242526272829@Service@Slf4jpublic class RegistrationCompensationCoordinator { @Autowired private ApplicationEventPublisher eventPublisher; // 監聽各種失敗事件，決定是否觸發整體補償 @EventListener public void handleEmailFailed(EmailFailedEvent event) { log.warn(&quot;郵件發送失敗，但繼續流程，不觸發補償: {}&quot;, event.getUserId()); // 郵件失敗不影響主要功能，僅記錄日誌 } @EventListener public void handleProfileCreationFailed(ProfileCreationFailedEvent event) { log.error(&quot;個人檔案建立失敗，觸發整體補償: {}&quot;, event.getUserId()); // 發布註冊失敗事件，觸發所有服務的補償操作 RegistrationFailedEvent failedEvent = RegistrationFailedEvent.builder() .userId(event.getUserId()) .email(event.getEmail()) .reason(&quot;個人檔案建立失敗: &quot; + event.getReason()) .timestamp(LocalDateTime.now()) .build(); eventPublisher.publishEvent(failedEvent); }} 基本上可以總結: 事件導向 每個服務只監聽自己關心的事件 透過事件自然驅動流程 鬆散耦合 郵件服務和個人檔案服務彼此不知道對方存在 可以獨立修改業務邏輯和演進 彈性錯誤處理 郵件失敗不影響主要流程 個人檔案失敗才觸發完整回滾 每個服務可以有自己的錯誤處理策略 Orchestrated Saga (協調式)協調式通常會由 一個協調者（Orchestrator/BFF） 負責編排整個流程，逐一呼叫 A -&gt; B -&gt; C, 根據結果決定下一步, 做決策補償、處理重試等機制。 好處是流程清晰易於管理，複雜業務邏輯集中, 但協調器成為單點，服務耦合度較高。 而 Casha Pos 創建餐廳帳號的流程正是由 BFF（Admin Portal）發起的兩步驟長交易。選用的原因如下: 流程明確：先建餐廳, 再建帳號，簡單的順序執行 業務邏輯集中：密碼生成、錯誤處理等邏輯在 BFF 統一管理 易於監控除錯：所有狀態變化都在協調器中，便於追蹤問題 補償機制清晰：當帳號建立失敗時，需要明確的禁用餐廳操作 Create Restaurant 實作前提Orchestrated Saga 實現在 Admin Portal 這個 BFF 的 CreateRestaurantUseCaseImpl 方法內。 其中錯誤狀態用 Global Exception Handler 補中自定義的錯誤, 詳情可參考 Casha 異常處置 微服務間以 Spring Cloud OpenFeign 溝通, 並設定 Resilience4j 重試。 123456789101112resilience4j: retry: instances: compensation-retry: maxAttempts: 2 # 重試2次 waitDuration: 1s # 等待1秒 retryExceptions: - org.springframework.web.client.HttpServerErrorException - java.net.ConnectException - java.io.IOException - feign.RetryableException - feign.FeignException 123@PostMapping(&quot;/store/restaurant/disable&quot;)@Retry(name = &quot;compensation-retry&quot;)ApiResponse&lt;Void&gt; disable(@RequestBody StoreDisableRestaurantRq rq); 核心流程 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112@Service@RequiredArgsConstructor@Slf4jpublic class CreateRestaurantUseCaseImpl implements CreateRestaurantUseCase { private static final String SAGA = &quot;CreateRestaurant&quot;; private static final char[] ALPHANUM = &quot;ABCDEFGHJKLMNPQRSTUVWXYZ23456789abcdefghjkmnpqrstuvwxyz&quot;.toCharArray(); private final StoreRestaurantClient storeClient; private final AuthProvisionClient authClient; private final SagaStatePort sagaState; private final CompensationEventPublisher eventPublisher; private final SecureRandom rnd = new SecureRandom(); @Override public CreateRestaurantRs create(CreateRestaurantRq rq) { // 冪等：同 txnId 直接回快取 CreateRestaurantRs cached = sagaState.get(SAGA, rq.getTxnId(), CreateRestaurantRs.class); if (cached != null) return cached; // 1) 先建餐廳（store） StoreCreateRestaurantRq srq = new StoreCreateRestaurantRq(); srq.setTxnId(rq.getTxnId()); srq.setName(rq.getName()); srq.setTaxId(rq.getTaxId()); srq.setIsActive(rq.getIsActive()); ApiResponse&lt;StoreCreateRestaurantRs&gt; sResp = storeClient.create(srq); if (!&quot;00000&quot;.equals(sResp.getResponseCode())) { throw new AdminPortalException(AdminPortalException.AdminPortalErrorType.STORE_CLIENT_FAIL); } String restaurantId = sResp.getData().getRestaurantId(); String code = sResp.getData().getCode(); String account = code + &quot;@casha.com&quot;; // 2) 生成 8 碼臨時密碼（由 BFF 產生，支援冪等重送） String tempPwd = genPassword(8); // 3) 建管理員時綁預設角色（auth） AuthProvisionAdminRq arq = new AuthProvisionAdminRq(); arq.setTxnId(rq.getTxnId()); arq.setRestaurantId(restaurantId); arq.setAccount(account); arq.setTempPassword(tempPwd); arq.setScope(&quot;RESTAURANT&quot;); try { ApiResponse&lt;AuthProvisionAdminRs&gt; aResp = authClient.provision(arq); if (!&quot;00000&quot;.equals(aResp.getResponseCode())) { // 業務錯誤 → 執行補償 log.info(&quot;AuthProvision 業務錯誤: 執行補償&quot;); compensateStore(restaurantId, rq.getTxnId(), &quot;AUTH_PROVISION_FAILED:&quot; + aResp.getMsg()); throw new AdminPortalException( AdminPortalException.AdminPortalErrorType.SAGA_COMPENSATION_FAIL); } } catch (FeignException e) { // Feign 異常 → 執行補償 log.info(&quot;AuthProvision Feign 異常: 執行補償: {}&quot;, e.getMessage()); compensateStore(restaurantId, rq.getTxnId(), &quot;AUTH_FEIGN_EXCEPTION:&quot; + e.getMessage()); throw new AdminPortalException( AdminPortalException.AdminPortalErrorType.SAGA_COMPENSATION_FAIL); } // 4) 成功 → 回傳一次性帳密，並存入 Saga 狀態（短 TTL） CreateRestaurantRs rs = new CreateRestaurantRs(restaurantId, code, account, tempPwd); sagaState.put(SAGA, rq.getTxnId(), rs, Duration.ofMinutes(30)); // 30 分鐘 TTL return rs; } private String genPassword(int n) { char[] buf = new char[n]; for (int i = 0; i &lt; n; i++) buf[i] = ALPHANUM[rnd.nextInt(ALPHANUM.length)]; return new String(buf); } // 提取補償邏輯到單獨方法 private void compensateStore(String restaurantId, String txnId, String reason) { StoreDisableRestaurantRq drq = new StoreDisableRestaurantRq(); drq.setTxnId(txnId); drq.setRestaurantId(restaurantId); drq.setReason(reason); try { // Resilience4j 對補償方法可設定 retry 2 次 storeClient.disable(drq); } catch (Exception ex) { log.error(&quot;補償禁用餐廳失敗，重試 {} 次後仍然失敗&quot;, 2, ex); // 發送 mq 去處理手動補償事件 StoreRestaurantDisablePayload payload = StoreRestaurantDisablePayload.builder() .txnId(drq.getTxnId()) .restaurantId(drq.getRestaurantId()) .build(); CompensationFailedEvent event = CompensationFailedEvent.builder() .transactionId(txnId) .serviceName(ModelType.ST) .reason(&quot;STORE_DISABLE:&quot; + reason) .failedAt(LocalDateTime.now()) .payload(payload) .build(); eventPublisher.publishCompensationFailed(event); } }} 可以看出來, 協調式 Saga 把複雜度集中在調節器上方，換來流程可控、語義穩定、易監控；代價是需要更嚴謹的狀態管理與韌性設計。 結語在微服務架構中，沒有銀彈，只有合適的選擇。其實我在一開始設計的時候就有想過這個業務應該用哪種方法做比較好, 老實說兩種方法其實都可以, 但就需要考慮到產生臨時密碼並同步, 以及同步/非同步等問題。 無論選擇哪種模式，重要的是理解背後的取捨，讓技術架構真正服務於業務","link":"/2025/10/02/casha-4-saga/"},{"title":"Casha | 5. 快取兩三事 - 雪崩, 擊穿和穿透介紹與範例解析","text":"最近開始整理 Casha 的快取設計, 剛好有一些現成的案例可以講解, 順便把快取會遇到的一些問題與解法整理起來。 快取的地雷以 F&amp;B 系統來說, 在正午 12 點的時候一間餐廳湧入大量客戶, 在這個區間內同時瀏覽菜單, 為了緩解 DB 的壓力, 我們設定首次查詢時, 先嘗試從 Redis 讀取緩存, 若 Redis 內沒有菜單, 則從 DB 獲取, 並寫入 Redis 後返回。 快取雪崩 Cache Avalanche泛指大量快取 Key 在同一時間大規模失效，導致所有請求瞬間湧向資料庫，造成資料庫壓力暴增甚至到崩潰。 通常發生的原因是: 設定了相同的 TTL (Time To Live),導致大量快取同時到期(失效) 快取的伺服器重啟或是崩潰 以 F&amp;B 系統為例, 就是每家餐廳都設定了菜單快取是 180s, 正午的時候流量湧進, 剛好在第 180s 的時候大家的快取同時失效, 每一家餐廳的菜單在這時全部都要從資料庫查找導致系統出問題。 常見的解法是 設定 TTL 抖動： 在專案內每家餐廳的菜單是設定 180 ± (180 * 20%)s 的隨機 TTL。確保了大量快取不會在同一時刻失效，避免了重建請求的洪峰。而針對一些常數類型的參數甚至可以儲存在 final 物件或 caffeine 裡面, 由服務啟動時載入, 並且不設定過期時間。 另外補充在高峰期到來之前, 還可以預熱快取, 先把可能被高頻訪問的資料觸發放置到 Redis 內。若菜單被更新, 則發送事件, 由監聽機制去更新快取內的菜單 (但應該不會有人這麼白目在高流量的時候還給我改資料吧, 應該吧…)。 快取擊穿 Hotspot Invalid指某個超高度被訪問的 Key 失效時，大量併發請求同時湧向這個 Key，直接一路穿透到資料庫。跟快取雪崩不太一樣的是通常是針對指定的一個 Key, 因此無法靠抖動解決(只有自己是要抖什麼)。 好比我設定了折價券資訊的快取, 但是當他失效時, 所有針對折價券資訊的請求又都會湧向 DB。 常見的解法是設定該 Key 的快取永不過期，由後台手動管理更新(適合少量需要特別照顧的熱點資料)。 第二個是使用分散式鎖機制：當快取失效時，只有一個執行緒（獲取鎖的）能去重建快取，其他執行緒會等待或降級。 在 Casha 中針對菜單其實也做了這一套防護, 當請求來臨時, 使用 Redis 的 SET key value NX EX timeout 指令獲取鎖，並透過 Lua 腳本保證釋放鎖的原子性, 到下游獲取資料，同時未能拿到鎖的請求主動睡眠一段短時間（50–150ms），以等待那個持有鎖的執行緒完成快取寫入，待睡眠結束後，再次嘗試從快取中讀取資料。 如果不幸退避等待後，快取依然為空（可能持有鎖的執行緒執行非常慢，或在寫入快取前失敗了），則不再等待，而是直接降級呼叫下游服務。雖然這違背了防止擊穿的初衷，但作為最後的保障，它保證了系統的可用性（寧可少量請求擊穿，也不能讓所有請求失敗）。同時，它也會將獲取到的結果寫入快取，以服務後續的請求。 但當然, 這些機制都要仰賴實際的業務需求來設計 詳見菜單緩存機制。 快取穿透 Cache Penetration請求根本不存在的資料，所以會繞過快取直接查詢資料庫。 這種請求通常是惡意的(排除你我寫了 Bug… 正常使用者不會請求不存在的資料的)，好比他發了一個 productId = -1 的請求, 可能是從 http.get 的 url 上更改, 有夠白目, 或是有人使用 proxy 偽造網站的請求。 解決方案則是: 請求參數驗證: 對參數格式、正則檢驗、參數範圍 設置布隆過濾器：快速判斷資料是否存在 空值快取：將不存在的結果也快取起來 限流策略：對異常請求模式進行限流 驗證參數大家都懂, 針對設計的規則與範圍判斷錯誤回拋 Exception, 請求根本碰不到 DB, 甚至可以搭配限流策略, 若特定的 Exception 被拋出太多次, 則在 Cache 內設定黑名單, 讓後續該 ip 的請求在 gateway 就被擋下來。 空值快取我第一次聽到的時候就想原來還有這招, 在特定的情境下或許該條件暫時不會有資料, 好比一家分店的菜單查詢下面並沒有對應的版本(早餐午餐交替的時間可能有幾分鐘的清場), 查到一個空菜單, 便可以設定空結果和較短的 TTL（如 30-60秒），避免快取污染同時又能防護短時間內的重複攻擊。 最後是布隆過濾器, 簡單來說是設計在服務啟動的時候, 從 DB 內把所有有效資料 (假定是 productId List) 取出, 並以雜湊的方式建立一個 ReadOnly 的濾器物件, 這個物件通常會是一個 BitSet, 常常會被稱為 Bloom (這是設計這個方法的人的名子), 每次請求的時候, 會用請求的 productId 進行雜湊後, 再和 Bloom 核對, 可以想像成是一個快速的過濾器。 舉個例子, 我先建立一個長度 m = 18 的 BitSet, 裡面預設都是 0, 我有兩個合法的 productId BRC001, DIN001, 我使用雜湊函式(具體實踐略) 做出 3 個索引: BRC001 假設做出來的索引是 {5, 11, 14}, DIN001 的是 {2, 11, 17}, 則我們把前面的 BitSet 內, {2, 5, 11, 14, 17} 鍵內的值都從 0 改為 1。所以當正常請求 BRTP001 查入時, 由雜湊函式算出來 {5, 11, 14}, 對應到 BitSet 內全都是 1, 則表示他可能存在, 就放過通行。但假使來個 FAKE000, 雜湊出來可能是 {1, 7, 11}，索引內 1 和 7 的值都是 0, 就可以判斷一定不存在。 他有極低的機率會錯放, 但已經可以過濾掉大部分的場景了, 且這個 BitSet 占用的空間也不大, 不過在有新的 id 置入時, Bloom 也就需要更新。 預防快取穿透通常會整合上面的方法, 參數驗證 (阻擋明顯非法請求) &gt; 布隆過濾器 (阻擋一定不存在的請求, 極低錯放) &gt; 空值快取 (處理偶然的不存在請求) 結語寫到這裡大家其實可以發現, 面對這些快取的議題, 除了依靠技術解決外, 最重要的還是了解核心業務流程, 才能選用最適合的方法。 最後想了解我對菜單在 Redis 上的設計可以參考我寫的 菜單緩存機制。","link":"/2025/10/04/casha-5-cache/"},{"title":"OOP 與 SOLID：從 Controller–Service–Repository 到 Clean Architecture","text":"好幾年前在之前的公司曾帶過幾個資策會出來的學弟。 記得剛 On Board 時我給他們幾個作業，Code Review 的時候也特別強調「要符合專案的架構風格與一些設計原則」。其實對 Junior 來說，他們以前專注的是「程式能不能跑、結果對不對」，效能、維護性、延展性這些詞，對當時的他們來說太遠了。 另外套句我碩士教授說的： 「你們那個系統沒多少人用，吹毛求疵那個效能幹嘛，不如把時間花在其他事情上。」 如今我已經在能反駁他的職位與工作需求上，發現畢業七八年後的我才真正體會那句話背後的現實。 軟體一旦上線，性能與維護都是長期成本。好的程式能提升協作效率，能降低 review、除錯、交接甚至是升級的時間。 而 OOP 與 SOLID，正是這些「長期維護成本」的根本解方。 OOP：物件導向程式設計的起點OOP 的四大核心是： 封裝（Encapsulation）、抽象（Abstraction）、繼承（Inheritance）、多型（Polymorphism） 目的是讓系統更容易維護、復用與擴充。 範例：顧客下單（Place Order）以下是一個典型的 Spring 三層架構範例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061@RestController@RequiredArgsConstructor@RequestMapping(&quot;/orders&quot;)public class OrderController { private final OrderService orderService; @PostMapping public PlaceOrderRs place(@RequestBody PlaceOrderRq rq) { return orderService.place(rq); }}@Service@RequiredArgsConstructorpublic class OrderService extends BaseService { private final ItemRepository itemRepository; private final OrderRepository orderRepository; private final RabbitTemplate rabbitTemplate; private static final String ORDER_EXCHANGE = &quot;order.events&quot;; private static final String ORDER_PLACED_RK = &quot;order.placed&quot;; @Transactional public PlaceOrderRs place(PlaceOrderRq rq) { require(rq != null, &quot;request must not be null&quot;); require(!rq.getLines().isEmpty(), &quot;lines must not be empty&quot;); BigDecimal total = BigDecimal.ZERO; List&lt;OrderLineEntity&gt; lines = new ArrayList&lt;&gt;(); for (OrderLineRq line : rq.getLines()) { var item = itemRepository.findById(Long.parseLong(line.getItemId())) .orElseThrow(() -&gt; bad(&quot;item not found: &quot; + line.getItemId())); require(line.getQty() &gt; 0, &quot;qty must &gt; 0&quot;); BigDecimal amount = item.getPrice().multiply(BigDecimal.valueOf(line.getQty())); total = total.add(amount); lines.add(new OrderLineEntity(item.getId(), item.getName(), item.getPrice(), line.getQty())); } OrderEntity order = new OrderEntity(); order.setTotal(total); order.setStatus(&quot;PLACED&quot;); order.setLines(lines); updateAuditFields(order); // 審計欄位統一更新 var saved = orderRepository.save(order); publishOrderPlaced(saved); return new PlaceOrderRs(saved.getId().toString(), total); } private void publishOrderPlaced(OrderEntity order) { var event = new OrderPlacedEvent(order.getId(), order.getTotal(), order.getLines().stream() .map(l -&gt; new OrderPlacedEvent.Line(l.getItemId(), l.getItemName(), l.getPriceSnapshot(), l.getQty())) .toList()); rabbitTemplate.convertAndSend(ORDER_EXCHANGE, ORDER_PLACED_RK, event); }} 123456789101112131415161718@Slf4jpublic abstract class BaseService { @Autowired protected Clock clock; protected void updateAuditFields(Auditable entity) { var now = LocalDateTime.now(clock); if (entity.getCreatedAt() == null) entity.setCreatedAt(now); entity.setUpdatedAt(now); } protected void require(boolean condition, String msg) { if (!condition) throw new IllegalArgumentException(msg); } protected RuntimeException bad(String msg) { return new IllegalArgumentException(msg); }} 三層架構下的 OOP封裝 (Encapsulation) 的概念是把資料與行為包在一起，外界只透過方法使用物件，不直接操作內部狀態。 例如 OrderLineEntity 內有 private 的 total 物件, 並提供 public 的 getter, setter 方法調用；OrderService 封裝下單流程，Controller 只要呼叫 place()。藉由封裝可以隱藏內部實作，只暴露必要介面，也就是說，外部只應該看到物件能做什麼，而不需要知道它怎麼做。 抽象 (Abstraction) 隱藏細節，讓使用者只看到介面層次。 Controller 不知道 DB 細節，只知道有個 OrderService.place(), 而 Service 只依賴抽象的 PaymentRepository，不在乎底層是 MySQL、PostgreSQL 或是外部 API。 這樣一來，當需求變動時，我們能在不修改 Service 的情況下自由替換底層實作。 繼承 (Inheritance) 繼承的目的，是共用行為並延伸差異。這裡的 updateAuditFields 就是繼承 (Inheritance) 的實例，統一管理審計欄位更新，而 OrderService 在下單邏輯中直接呼叫它完成欄位更新。 多型 (Polymorphism) 同一介面可有不同實作，執行時依物件而異。 不同 OrderRepository（JPA、MyBatis、Mock）都能被注入運作。 OOP 的侷限上述是常見的三層架構, 好讀好理解, 但其實暗藏地雷: OrderService 同時負責驗證、計算、組訂單、發事件，違反單一職責原則。 若要加上「折扣」、「定價策略」或「不同事件通道」，都得改動 OrderService。 測試難度高，耦合嚴重，會讓大家只想寫 Happy Path。 接下來，我們用 SOLID 原則 將這段程式「演化」成可長期維護的架構。 SOLID：讓 OOP 真正能長大的五個原則重構前後對照：從 Controller-Service 到 Clean Architecture重構前 - 傳統三層架構： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@RestController@RequiredArgsConstructor@RequestMapping(&quot;/orders&quot;)public class OrderController { private final OrderService orderService; @PostMapping public PlaceOrderRs place(@RequestBody PlaceOrderRq rq) { return orderService.place(rq); }}@Service@RequiredArgsConstructorpublic class OrderService extends BaseService { private final ItemRepository itemRepository; private final OrderRepository orderRepository; private final RabbitTemplate rabbitTemplate; @Transactional public PlaceOrderRs place(PlaceOrderRq rq) { // 混合了驗證、計算、組裝、保存、發事件等多重職責 require(rq != null, &quot;request must not be null&quot;); require(!rq.getLines().isEmpty(), &quot;lines must not be empty&quot;); BigDecimal total = BigDecimal.ZERO; List&lt;OrderLineEntity&gt; lines = new ArrayList&lt;&gt;(); // 價格計算邏輯硬編碼在服務中 for (OrderLineRq line : rq.getLines()) { var item = itemRepository.findById(Long.parseLong(line.getItemId())) .orElseThrow(() -&gt; bad(&quot;item not found: &quot; + line.getItemId())); require(line.getQty() &gt; 0, &quot;qty must &gt; 0&quot;); BigDecimal amount = item.getPrice().multiply(BigDecimal.valueOf(line.getQty())); total = total.add(amount); lines.add(new OrderLineEntity(item.getId(), item.getName(), item.getPrice(), line.getQty())); } OrderEntity order = new OrderEntity(); order.setTotal(total); order.setStatus(&quot;PLACED&quot;); order.setLines(lines); updateAuditFields(order); var saved = orderRepository.save(order); publishOrderPlaced(saved); // 直接依賴具體的 RabbitMQ return new PlaceOrderRs(saved.getId().toString(), total); }} 重構後 - Clean Architecture： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586// Controller 保持精簡，專注於 HTTP 相關事務@RestController@RequiredArgsConstructor@RequestMapping(&quot;/orders&quot;)public class OrderController { private final PlaceOrderUseCase placeOrderUseCase; @PostMapping public PlaceOrderResponse place(@RequestBody PlaceOrderRequest request) { var command = new PlaceOrderCommand( request.customerId(), request.lines().stream() .map(l -&gt; new PlaceOrderCommand.PlaceOrderLine(l.itemId(), l.qty())) .toList() ); var result = placeOrderUseCase.execute(command); return new PlaceOrderResponse(result.orderId(), result.total()); }}// UseCase 專注於業務流程協調@Service@RequiredArgsConstructorpublic class PlaceOrderUseCaseImpl implements PlaceOrderUseCase { private final ItemGateway itemGateway; private final OrderGateway orderGateway; private final EventPublisher eventPublisher; private final PricingPolicy pricingPolicy; private final Clock clock; @Transactional public PlaceOrderResult execute(PlaceOrderCommand cmd) { // 使用領域模型封裝業務邏輯 var order = new Order(); for (var line : cmd.lines()) { var item = itemGateway.findById(Long.parseLong(line.itemId())) .orElseThrow(() -&gt; new IllegalArgumentException(&quot;item not found&quot;)); var unitPrice = pricingPolicy.unitPriceFor(item, line.qty()); order.addLine(item, line.qty(), unitPrice); // 業務邏輯移至領域模型 } order.place(); // 領域行為 order.touch(LocalDateTime.now(clock)); var saved = orderGateway.save(order); eventPublisher.publishOrderPlaced(saved); return new PlaceOrderResult(saved.getId().toString(), saved.getTotal()); }}// 豐富的領域模型public class Order { private OrderId id; private List&lt;OrderLine&gt; lines = new ArrayList&lt;&gt;(); private BigDecimal total = BigDecimal.ZERO; private OrderStatus status; private LocalDateTime createdAt; private LocalDateTime updatedAt; public void addLine(Item item, int quantity, BigDecimal unitPrice) { require(quantity &gt; 0, &quot;Quantity must be positive&quot;); require(unitPrice.compareTo(BigDecimal.ZERO) &gt;= 0, &quot;Unit price must be non-negative&quot;); var line = new OrderLine(item.id(), item.name(), unitPrice, quantity); lines.add(line); total = total.add(line.subTotal()); } public void place() { require(!lines.isEmpty(), &quot;Cannot place order with no lines&quot;); this.status = OrderStatus.PLACED; } // 新增 touch 方法來處理審計欄位更新 public void touch(LocalDateTime timestamp) { if (this.createdAt == null) { this.createdAt = timestamp; } this.updatedAt = timestamp; } // 封裝內部實現細節 public BigDecimal getTotal() { return total; } public OrderStatus getStatus() { return status; }} 對照分析 維度 重構前 (Controller-Service) 重構後 (Clean Architecture) 職責分離 Service 承擔多重職責 UseCase 協調，Domain 封裝邏輯 業務邏輯 散落在 Service 方法中 集中在領域模型內 測試難度 需要整合測試，耦合嚴重 可單元測試各組件 擴充性 修改現有類別 新增策略類別，符合開放封閉 依賴方向 依賴具體框架技術 依賴抽象接口 S：單一職責原則（Single Responsibility）重構前問題： OrderService 同時負責： 請求驗證 價格計算 訂單組裝 資料保存 事件發布 重構後解決： PlaceOrderUseCase：協調業務流程 Order 領域模型：封裝訂單業務規則 PricingPolicy：專注定價策略 EventPublisher：處理事件發布 O：開放封閉原則（Open/Closed Principle）重構前問題： 新增定價策略需要修改 OrderService： 12345678// 舊方式：在 Service 中硬編碼判斷if (isCampaignPeriod()) { price = item.getPrice().multiply(new BigDecimal(&quot;0.9&quot;));} else if (isMemberPrice(user)) { price = item.getPrice().multiply(new BigDecimal(&quot;0.95&quot;));} else { price = item.getPrice();} 重構後解決： 透過策略模式擴充： 1234567891011121314151617public interface PricingPolicy { BigDecimal unitPriceFor(Item item, int qty);}@Componentclass StandardPricingPolicy implements PricingPolicy { public BigDecimal unitPriceFor(Item item, int qty) { return item.price(); }}@Componentclass MemberPricingPolicy implements PricingPolicy { public BigDecimal unitPriceFor(Item item, int qty) { return item.price().multiply(new BigDecimal(&quot;0.95&quot;)); }} L：里氏替換原則（Liskov Substitution Principle）重構前問題： 直接依賴 Spring Data JPA： 1private final OrderRepository orderRepository; // Spring Data 接口 重構後解決： 自定義 Gateway 接口： 12345678910public interface OrderGateway { Order save(Order order); Optional&lt;Order&gt; findById(OrderId id);}@Repositoryclass JpaOrderGateway implements OrderGateway { private final SpringDataOrderJpa jpa; // 實作細節封裝在基礎設施層} I：介面隔離原則（Interface Segregation Principle）重構前問題： Repository 介面可能過於龐大： 123public interface OrderRepository extends JpaRepository&lt;OrderEntity, Long&gt; { // 可能包含數十個方法，即使某些 UseCase 只需要其中幾個} 重構後解決： 按職責分離接口： 1234567891011public interface ItemGateway { Optional&lt;Item&gt; findById(Long id);}public interface OrderGateway { Order save(Order order);}public interface EventPublisher { void publishOrderPlaced(Order order);} D：依賴反轉原則（Dependency Inversion Principle）重構前問題： 高層模組依賴低層模組： 123Controller → Service → Repository (JPA) → Database ↓ RabbitTemplate → Message Queue 重構後解決： 高層定義接口，低層實現： 123Controller → UseCase (業務邏輯) ↓ Ports (接口定義) ← Adapters (實作) 結論, 追求更好的環境最後整理了結論: 三層架構在專案初期很快，但當業務複雜度成長時，修改一個功能可能引發多處變動 Clean Architecture 透過依賴反轉和介面隔離，讓系統能夠優雅地適應變化 清晰的架構邊界讓多人開發時減少衝突 新成員能透過架構快速理解業務邏輯的分佈 重構前：OrderService 的測試需要準備大量 Mock，測試程式碼複雜 重構後：每個組件都可以獨立測試，測試程式碼更專注、更簡單 當需要更換資料庫、消息隊列或框架時，Clean Architecture 讓這些變更侷限在基礎設施層，不影響核心業務邏輯 回頭看教授當年的那句話：「你們那個系統沒多少人用，吹毛求疵那個效能幹嘛」，我現在有了更深的理解。他說的其實是成本效益的權衡——在資源有限的情況下，應該把精力花在刀刃上。 說實在, 如果三層式架構這麼多毛病, 怎麼還沒被淘汰呢? 反過來說, 若三層式架構就足夠應付業務邏輯, 還能快速交付, 又為何不使用呢? 在這種環境下，我們也只能更努力的去追求更好, 資源與需求更大的企業，然後保持學習與對程式品質的初心。","link":"/2025/10/09/solid/"},{"title":"2025 成都上海遊","text":"2025 年, 在銀行翻新案順利結束後, 我離開了 IBM, 加入易鑫集團在台灣的汽車融資軟體服務分公司, 在拿到 offer 後, 終於能真正的放鬆一下, 就立刻安排了一趟大陸自由行, 由於我的戶籍在金門, 就到老家住一天, 再走小三通從廈門出發, 到成都與上海玩 10 天, 在地圖上畫上了一個大大的三角形。 出發前天氣還可以, 先在鍾鼓索道搭纜車, 纜車內部沒有窗戶, 風都直接吹在身上, 還好沒有懼高症, 算愜意的瀏覽廈門雙子塔, 今年五月跟我爸來處理家族事宜就有去過裡面, 可惜到雙子塔的時候已經是晚上, 上面的觀景台沒開放, 這次在廈門也只待半天, 等後面有機會再來一趟吧。 傍晚就搭了飛機前往成都, 在寬窄巷子內先吃了一波遊客餐, 包含老媽兔頭, 還有腦花等獵奇食物, 真的是需要一些心理建設才敢開口… 好笑的是在訂機票的時候我注意到成都有天府和雙流兩個機場, 我想說難得一趟就安排一個來一個去, 結果買完機票猛然一驚, 看了一下天府機場到成都市中心要一個半小時的車程, 還好有直達巴士, 頭有夠痛。 隔天預訂了一日旅行團上峨嵋山, 我在山下才知道前一晚峨嵋山頂下雪, 現在上面只有 6 度, 我還穿短袖配薄外套, 只好在山下買毛帽和雨衣當衝鋒衣硬扛了一天。山頂沒有師太, 沒有黃飛虎, 沒有人練傷心斷腸劍(知道這個梗的人也不年輕了), 只有超濃的霧與拜拜的遊客, 山的路上有一大群猴子, 要是拎著塑膠袋他們就會衝過來搶, 有夠野蠻。 接著又去熊貓谷看熊貓, 原來小的那種叫做 Red Panda, 下午再去看都江堰，當我第一次在高樓看都江堰的設計, 真的有被古人的智慧驚艷到, 他整個水利工程的核心是這六個字: 深淘灘, 低做堰 概念上是指深層淘洗河床，低矮修築堤堰, 藉由分兩道水流, 左道淺而寬, 右道窄而深, 在洪水季節排沙減洪，在枯水季節引水灌田, 一切都只用分流與水速, 沒有做任何閘道, 真是優雅的設計。小時候在上地理課聽都江堰一點感覺都沒有, 果然還是要親眼看過才有辦法想像。 最好笑的是同行的馬來西亞女生和俄羅斯家庭都不清楚中國的歷史, 導遊講三國他們滿頭問號, 只能尷尬的從我這裡取得一點認同 XD。經過分水口的時候還遇到一群紅領巾小學生出來校外教學, 他們很熱情的和俄羅斯夫婦 say hello, 看到我們則快步走開, 馬來西亞搭子表示忌妒跟我 murmur (倫家也是外國人啊 QAQ)。 最後一天自由行, 在成都市區看 IFS 大熊貓, 逛武侯祠, 相親角, 吃冒烤鴨等, 成都吃得有夠辣, 每餐必咳, 然後會胃痛, 我跟老闆說你給我福建的辣度就好, 他說你們福建末得吃辣der, 俺給你做個微微辣, 上菜後嚐一口, 辣他媽的。 最後則是在成都的小酒館 大冰的小屋 內喝酒聽駐唱, 我點了一首旅行的意義, 散場前大夥拱歌手唱成都, 他苦著臉說你們這些外地人一天到晚都讓我唱這首歌(最後還是唱了)。 成都結束後前往上海, 去見了 20 年的髮小，一起沿著黃浦江聊天敘舊, 走了一整個下午，小的時候還常常到元智大學裡面踢足球, 如今都 被社會摧殘 成這副模樣了。 晚上又到了上海的 Downtown Swing 跳舞, 周末剛好遇到萬聖節舞會, 還給了我一個 Welcome Jam。我似乎做了一個不錯的 Ending Pose~~ 最後一天到上海迪士尼玩, 8:30 am 一到大家像瘋了一樣往裡面衝, 明明是周一還有 6 ~ 7 萬的人流, 還真是誇張。雖然我個人覺得上海迪士尼的煙火還是有一點水，但整天玩下來還是很有喜悅的感覺，會覺得夢想真的會實現。 飛回廈門後, 晚上又到來瘋喜劇看 openMic, 感覺和台灣的卡米地很不一樣, 幾乎沒有政治與火烤文化, 更多是對生命的自嘲。 這好像也是我去年更新成 Hexo 後第一次打這種流水帳遊記，之前工作都是休息一周後馬上開工, 幾乎是無縫接軌, 這次好不容易安排了兩周的時間, 可以好好地放鬆一下, 下一次還有這樣的機會, 不知道是什麼時候了。","link":"/2025/11/08/china-travel-2025/"}],"tags":[{"name":"chit-chat","slug":"chit-chat","link":"/tags/chit-chat/"},{"name":"develop","slug":"develop","link":"/tags/develop/"},{"name":"Exception","slug":"Exception","link":"/tags/Exception/"},{"name":"DB","slug":"DB","link":"/tags/DB/"},{"name":"Life","slug":"Life","link":"/tags/Life/"},{"name":"colorly","slug":"colorly","link":"/tags/colorly/"},{"name":"Spring Cloud","slug":"Spring-Cloud","link":"/tags/Spring-Cloud/"},{"name":"Clean Architecture","slug":"Clean-Architecture","link":"/tags/Clean-Architecture/"},{"name":"SDLC","slug":"SDLC","link":"/tags/SDLC/"},{"name":"github Actions","slug":"github-Actions","link":"/tags/github-Actions/"},{"name":"DevOps","slug":"DevOps","link":"/tags/DevOps/"},{"name":"Agile","slug":"Agile","link":"/tags/Agile/"},{"name":"Casha","slug":"Casha","link":"/tags/Casha/"},{"name":"Redis","slug":"Redis","link":"/tags/Redis/"},{"name":"MQ","slug":"MQ","link":"/tags/MQ/"},{"name":"RBAC","slug":"RBAC","link":"/tags/RBAC/"},{"name":"System Design","slug":"System-Design","link":"/tags/System-Design/"},{"name":"Jmeter","slug":"Jmeter","link":"/tags/Jmeter/"},{"name":"Observation","slug":"Observation","link":"/tags/Observation/"},{"name":"Grafana","slug":"Grafana","link":"/tags/Grafana/"},{"name":"Prometheus","slug":"Prometheus","link":"/tags/Prometheus/"},{"name":"Saga","slug":"Saga","link":"/tags/Saga/"},{"name":"Cache","slug":"Cache","link":"/tags/Cache/"},{"name":"SOLID","slug":"SOLID","link":"/tags/SOLID/"},{"name":"Design Pattern","slug":"Design-Pattern","link":"/tags/Design-Pattern/"}],"categories":[{"name":"Life","slug":"Life","link":"/categories/Life/"},{"name":"Troll","slug":"Troll","link":"/categories/Troll/"},{"name":"Development","slug":"Development","link":"/categories/Development/"},{"name":"Design Pattern","slug":"Design-Pattern","link":"/categories/Design-Pattern/"}],"pages":[{"title":"關於我","text":"我是 William Wu, 現任職於新加坡 X-star 台灣分公司，主要從事 Java Backend、DevOps 在新加坡車貸與金融領域的開發。 Williamrightone/km-book 是我於 2022 年七月起用於紀錄學習、分享技術與 Side Project 的專案，期間經歷 GitBook, Hugo 到近期嘗使用 Hexo，偶而會分享一些生活的心得。 除了自我學習以外，也希望能幫助到遭遇相同問題的人 我們不需要很厲害才能開始，但一定要開始後才能很厲害 不定期更新，若內容有需修正的地方也請不吝通知我~s Willy4543@gmail.comhttps://www.cake.me/willy4543 剛出社會的時候大學同學遺忘糾露營、早期又揪不到人組團參加 It Iron-man，被戲稱 孤單威廉，另外我也是一位 Lindy Hop Dancer, 或許有一天我們會在舞池相遇。","link":"/about/index.html"}]}